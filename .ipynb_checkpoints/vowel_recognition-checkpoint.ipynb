{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import librosa\n",
    "import scipy\n",
    "import scipy.signal as sig\n",
    "import scipy.io.wavfile as scw\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import wave\n",
    "import cmath as cm\n",
    "import math\n",
    "\n",
    "import default_settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preparation : define extract_feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levinson(signal, order):\n",
    "    x = signal\n",
    "    p = order\n",
    "    autocorr = np.correlate(x,x,mode='full')\n",
    "    r = autocorr[len(x)-1:len(x)+p]\n",
    "\n",
    "    a = np.zeros(p+1)\n",
    "    k = np.zeros(p)\n",
    "    a[0] = 1\n",
    "    a[1] = -r[1] / r[0]\n",
    "    k[0] = a[1]\n",
    "    E = r[0] + r[1] * a[1]\n",
    "    for q in range(1,p):\n",
    "        k[q] = -np.sum(a[0:q+1] * r[q+1:0:-1]) / E\n",
    "        U = a[0:q+2]\n",
    "        V = U[::-1]\n",
    "        a[0:q+2] = U + k[q] * V\n",
    "        E *= 1-k[q] * k[q]\n",
    "\n",
    "    return a, k\n",
    "\n",
    "\n",
    "def preEmphasis(signal, p):\n",
    "    return sig.lfilter([1.0, -p], 1, signal)\n",
    "\n",
    "\n",
    "def autocorr(x, nlags=None):\n",
    "    N = len(x)\n",
    "    if nlags == None: nlags = N\n",
    "    r = np.zeros(nlags)\n",
    "    for lag in range(nlags):\n",
    "        for n in range(N - lag):\n",
    "            r[lag] += x[n] * x[n + lag]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT(x):\n",
    "    N = x.shape[0]\n",
    "    \n",
    "    # Recursive processing end confirmation\n",
    "    if N==1:\n",
    "        return x[0]\n",
    "    \n",
    "    x_even = x[0:N:2]\n",
    "    x_odd = x[1:N:2]\n",
    "    \n",
    "    # Recursive processing\n",
    "    X_even = FFT(x_even)\n",
    "    X_odd = FFT(x_odd)\n",
    "    \n",
    "    # weight\n",
    "    W = []\n",
    "    for t in range(N//2):\n",
    "        W.append(np.exp(-1j * ((2*np.pi*t) / N)))\n",
    "    W = np.array(W)\n",
    "    \n",
    "    X = np.zeros(N, dtype=\"complex\")\n",
    "    X[0:N//2] = X_even + W*X_odd\n",
    "    X[N//2:N] = X_even - W*X_odd\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def IFFT(X):\n",
    "    N = X.shape[0]\n",
    "    X = X.conjugate()\n",
    "    x = FFT(X)\n",
    "    return (1/N) * x.conjugate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_formant(x, deg, fs=22050):\n",
    "    a, k = levinson(x,deg)\n",
    "    \n",
    "    w, h = sig.freqz(1, a)\n",
    "    #fig = plt.figure()\n",
    "    #ax = fig.add_subplot(111)\n",
    "    #ax.plot(fs * w / 2.0 / np.pi, 20 * np.log10(np.abs(h)))\n",
    "    #ax.set_xlabel('frequency [Hz]')\n",
    "    #ax.set_ylabel('$1 / |A(e^{j\\omega})|$ [dB]')\n",
    "    #plt.show()\n",
    "    \n",
    "    poles = np.roots(a)\n",
    "    intns = np.abs(poles)\n",
    "    ff = np.angle(poles) * fs / 2.0 / np.pi\n",
    "    formantfreq = ff[(ff > 10) & (ff < fs / 2.0 - 10) & (intns > 0.8)]\n",
    "\n",
    "    return formantfreq\n",
    "\n",
    "\n",
    "def extract_cepstrum(x, deg, fs=22050):\n",
    "    fft_data_ori = FFT(x)\n",
    "    freq_ori = np.arange(len(fft_data_ori)) * fs / len(fft_data_ori)\n",
    "    pow_spec = np.log10(np.real(np.abs(fft_data_ori)**2))\n",
    "    cep = IFFT(pow_spec)\n",
    "    return cep[:deg]\n",
    "\n",
    "\n",
    "def extract_mfcc(x, deg, fs=22050):\n",
    "    if len(x) <= 2048:\n",
    "        mfcc = librosa.feature.mfcc(y=x, sr=fs ,n_mfcc=deg, n_fft=len(x))\n",
    "    else:\n",
    "        mfcc = librosa.feature.mfcc(y=x, sr=fs ,n_mfcc=deg)\n",
    "    mfcc = np.average(mfcc, axis = 1)\n",
    "    \n",
    "    mfcc = mfcc.flatten()\n",
    "    mfcc = mfcc.tolist()\n",
    "    \n",
    "    mfcc.pop(0)\n",
    "    mfcc = mfcc[:12]\n",
    "    return mfcc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_sample_dir = default_settings.vowel_dir\n",
    "output_features_dir = default_settings.features_dir\n",
    "wav_files = os.listdir(speech_sample_dir)\n",
    "\n",
    "fmt_dir = os.path.join(output_features_dir, 'fmt')\n",
    "cep_dir = os.path.join(output_features_dir, 'cep')\n",
    "mfcc_dir = os.path.join(output_features_dir, 'mfcc')\n",
    "\n",
    "if not os.path.exists(fmt_dir):\n",
    "    os.makedirs(fmt_dir)\n",
    "if not os.path.exists(cep_dir):\n",
    "    os.makedirs(cep_dir)\n",
    "if not os.path.exists(mfcc_dir):\n",
    "    os.makedirs(mfcc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# formant data\n",
    "FORMANT = []\n",
    "# label data\n",
    "LABEL = []\n",
    "# mfcc data\n",
    "MFCC = []\n",
    "\n",
    "for wav_file in wav_files[:]:\n",
    "    basename_without_ext = os.path.splitext(os.path.basename(wav_file))[0]\n",
    "    label = basename_without_ext.split('_')[0]\n",
    "    fmt_file = os.path.join(fmt_dir, basename_without_ext + '_fmt')\n",
    "    cep_file = os.path.join(cep_dir, basename_without_ext + '_cep')\n",
    "    mfcc_file = os.path.join(mfcc_dir, basename_without_ext + '_mfcc')\n",
    "    \n",
    "    sampling_rate, sample_data = scw.read(os.path.join(speech_sample_dir, wav_file))\n",
    "    sample_data = sample_data / 32768\n",
    "    \n",
    "    return_formant = extract_formant(sample_data, 12, sampling_rate)\n",
    "    return_formant.sort()\n",
    "    return_cep = extract_cepstrum(sample_data[:512], 20, sampling_rate)\n",
    "    return_mfcc = extract_mfcc(sample_data, 20, sampling_rate)\n",
    "    \n",
    "    np.save(fmt_file, return_formant)\n",
    "    np.save(cep_file, return_cep)\n",
    "    np.save(mfcc_file, return_mfcc)\n",
    "    \n",
    "    FORMANT.append(return_formant[:2])\n",
    "    LABEL.append(label)\n",
    "    MFCC.append(return_mfcc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## speaker recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[359.82400534 957.03321564] a\n",
      "[ 359.04451134 2021.66558281] e\n",
      "[ 306.06734237 1747.6899365 ] u\n",
      "[ 404.5496131  1014.30122892] a\n",
      "[ 353.05055634 2194.33187911] e\n",
      "[ 378.39392655 2262.51245728] e\n",
      "[ 460.26505791 1058.80915514] a\n",
      "[ 295.01135656 3636.52262072] i\n",
      "[ 302.17198054 4147.16238536] u\n",
      "[ 345.14825776 1058.46995357] a\n",
      "[ 267.39156484 1817.82673725] i\n",
      "[ 340.99985517 2188.00319044] e\n",
      "[376.31457974 667.10529682] o\n",
      "[ 320.26443745 1587.18932047] u\n",
      "[332.92833882 690.6981292 ] o\n",
      "[ 288.33943439 1942.22690858] i\n",
      "[ 279.89810969 1904.97808096] i\n",
      "[ 369.85989109 1962.99734326] e\n",
      "[ 297.72149189 2132.6214949 ] i\n",
      "[361.42282642 959.70773645] a\n",
      "[ 319.42981491 4135.72748545] u\n",
      "[350.7695197  719.98433291] o\n",
      "[346.66673229 709.20542358] o\n",
      "[ 323.52325619 2027.31644856] u\n",
      "[350.17330499 651.90787812] o\n"
     ]
    }
   ],
   "source": [
    "for data, label in zip(FORMANT, LABEL):\n",
    "    print(data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formant vowel_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split feature data (use Formant) into 20 training data + 5 test data.\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(FORMANT, LABEL, train_size=0.8)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct label =  ['u' 'e' 'u' 'i' 'i']\n",
      "predict label =  ['u' 'e' 'e' 'e' 'e']\n",
      "correct answer rate =  0.4\n"
     ]
    }
   ],
   "source": [
    "## train SVM or logistic regression using the training data, and evaluate it with the test data.\n",
    "model = SVC(gamma='scale')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('correct label = ', y_test)\n",
    "print('predict label = ', model.predict(x_test))\n",
    "print('correct answer rate = ', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MFCC vowel_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## split feature data (use MFCC) into 20 training data + 5 test data.\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(MFCC, LABEL, train_size=0.8)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct label =  ['i' 'u' 'a' 'o' 'e']\n",
      "predict label =  ['i' 'u' 'a' 'o' 'e']\n",
      "correct answer rate =  1.0\n"
     ]
    }
   ],
   "source": [
    "## train SVM or logistic regression using the training data, and evaluate it with the test data.\n",
    "model = SVC(gamma='scale')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "print('correct label = ', y_test)\n",
    "print('predict label = ', model.predict(x_test))\n",
    "print('correct answer rate = ', model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make above 2 steps into one function.\n",
    "def speaker_recognition(feature_dir, n_train=20, n_test=5):\n",
    "    return accuracy_train, accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform cross validation i.e. n_train=24, n_test=1, \n",
    "## and take average of accuracies of all 25 combinations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
